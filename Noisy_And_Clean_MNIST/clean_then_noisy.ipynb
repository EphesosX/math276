{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noisy(mnist_image):\n",
    "    mnist_rand_image = np.copy(mnist_image)\n",
    "\n",
    "    for x in np.nditer(mnist_rand_image, op_flags=['readwrite']):\n",
    "        randval = np.random.randint(0,10)\n",
    "        if randval == 0:\n",
    "            x[...] = 0\n",
    "        elif randval == 1:\n",
    "            x[...] = 255\n",
    "            \n",
    "    return mnist_rand_image\n",
    "\n",
    "#plt.imshow(make_noisy(mnist_data[0][0][0]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noisy_clean_array = []\n",
    "train_data_size = mnist_data[0][0].shape[0]\n",
    "validation_split_size = 0.2\n",
    "actual_train_data_size = int(train_data_size * (1 - validation_split_size))\n",
    "\n",
    "# Training set\n",
    "for i in range(0, actual_train_data_size):\n",
    "    if (i < actual_train_data_size/2):\n",
    "        train_noisy_clean_array.append(make_noisy(mnist_data[0][0][i]))\n",
    "    else:\n",
    "        train_noisy_clean_array.append(mnist_data[0][0][i])\n",
    "\n",
    "# Validation set \n",
    "validation_data_size = train_data_size - actual_train_data_size\n",
    "\n",
    "for i in range(0, validation_data_size):\n",
    "    if (i < validation_data_size/2):\n",
    "        train_noisy_clean_array.append(make_noisy(mnist_data[0][0][i+actual_train_data_size]))\n",
    "    else:\n",
    "        train_noisy_clean_array.append(mnist_data[0][0][i+actual_train_data_size])\n",
    "\n",
    "train_noisy_clean_array = np.asarray(train_noisy_clean_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=mnist_data[0][1]\n",
    "test_labels=mnist_data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_then_clean_mnist = ((train_noisy_clean_array,train_labels),(mnist_data[1][0],test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_noisy_mnist_train = noisy_then_clean_mnist[0][0][0:24000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_clean_mnist_train = noisy_then_clean_mnist[0][0][24000:48000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_noisy_mnist_validation = noisy_then_clean_mnist[0][0][48000:48000+6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_clean_mnist_validation = noisy_then_clean_mnist[0][0][48000+6000:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_mnist_half_train_validation = np.concatenate((half_noisy_mnist_train, half_noisy_mnist_validation), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_mnist_half_train_validation = np.concatenate((half_clean_mnist_train, half_clean_mnist_validation), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_for_noisy_train_validation = np.concatenate((train_labels[0:24000],train_labels[48000:48000+6000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_for_clean_train_validation = np.concatenate((train_labels[24000:48000],train_labels[48000+6000:60000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_noisy_mnist = ((noisy_mnist_half_train_validation, labels_for_noisy_train_validation), (mnist_data[1][0], mnist_data[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_clean_mnist = ((clean_mnist_half_train_validation,labels_for_clean_train_validation), (mnist_data[1][0], mnist_data[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean data\n",
      "30000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "24000/24000 [==============================] - 1s 53us/step - loss: 0.4791 - acc: 0.8647 - val_loss: 0.2277 - val_acc: 0.9338\n",
      "Epoch 2/20\n",
      "24000/24000 [==============================] - 1s 46us/step - loss: 0.2390 - acc: 0.9305 - val_loss: 0.1719 - val_acc: 0.9535\n",
      "Epoch 3/20\n",
      "24000/24000 [==============================] - 1s 50us/step - loss: 0.1820 - acc: 0.9470 - val_loss: 0.1380 - val_acc: 0.9620\n",
      "Epoch 4/20\n",
      "24000/24000 [==============================] - 1s 48us/step - loss: 0.1433 - acc: 0.9608 - val_loss: 0.1236 - val_acc: 0.9650\n",
      "Epoch 5/20\n",
      "24000/24000 [==============================] - 1s 53us/step - loss: 0.1188 - acc: 0.9672 - val_loss: 0.1107 - val_acc: 0.9687\n",
      "Epoch 6/20\n",
      "24000/24000 [==============================] - 1s 52us/step - loss: 0.0988 - acc: 0.9743 - val_loss: 0.1034 - val_acc: 0.9708\n",
      "Epoch 7/20\n",
      "24000/24000 [==============================] - 2s 67us/step - loss: 0.0846 - acc: 0.9780 - val_loss: 0.0962 - val_acc: 0.9727\n",
      "Epoch 8/20\n",
      "24000/24000 [==============================] - 1s 53us/step - loss: 0.0726 - acc: 0.9808 - val_loss: 0.0906 - val_acc: 0.9743\n",
      "Epoch 9/20\n",
      "24000/24000 [==============================] - 1s 51us/step - loss: 0.0619 - acc: 0.9855 - val_loss: 0.0876 - val_acc: 0.9763\n",
      "Epoch 10/20\n",
      "24000/24000 [==============================] - 1s 59us/step - loss: 0.0545 - acc: 0.9871 - val_loss: 0.0869 - val_acc: 0.9747\n",
      "Epoch 11/20\n",
      "24000/24000 [==============================] - 1s 50us/step - loss: 0.0474 - acc: 0.9888 - val_loss: 0.0827 - val_acc: 0.9777\n",
      "Epoch 12/20\n",
      "24000/24000 [==============================] - 1s 50us/step - loss: 0.0413 - acc: 0.9916 - val_loss: 0.0839 - val_acc: 0.9758\n",
      "Epoch 13/20\n",
      "24000/24000 [==============================] - 1s 55us/step - loss: 0.0358 - acc: 0.9930 - val_loss: 0.0821 - val_acc: 0.9773\n",
      "Epoch 14/20\n",
      "24000/24000 [==============================] - 1s 50us/step - loss: 0.0319 - acc: 0.9937 - val_loss: 0.0819 - val_acc: 0.9768\n",
      "Epoch 15/20\n",
      "24000/24000 [==============================] - 1s 56us/step - loss: 0.0276 - acc: 0.9955 - val_loss: 0.0814 - val_acc: 0.9753\n",
      "Epoch 16/20\n",
      "24000/24000 [==============================] - 1s 52us/step - loss: 0.0249 - acc: 0.9956 - val_loss: 0.0811 - val_acc: 0.9773\n",
      "Epoch 17/20\n",
      "24000/24000 [==============================] - 1s 58us/step - loss: 0.0221 - acc: 0.9964 - val_loss: 0.0784 - val_acc: 0.9768\n",
      "Epoch 18/20\n",
      "24000/24000 [==============================] - 1s 54us/step - loss: 0.0201 - acc: 0.9972 - val_loss: 0.0804 - val_acc: 0.9782\n",
      "Epoch 19/20\n",
      "24000/24000 [==============================] - 1s 49us/step - loss: 0.0178 - acc: 0.9979 - val_loss: 0.0796 - val_acc: 0.9785\n",
      "Epoch 20/20\n",
      "24000/24000 [==============================] - 1s 54us/step - loss: 0.0161 - acc: 0.9984 - val_loss: 0.0771 - val_acc: 0.9780\n",
      "Test loss: 0.08853870153122116\n",
      "Test accuracy: 0.974\n",
      "Noisy data\n",
      "30000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "24000/24000 [==============================] - 1s 54us/step - loss: 0.2325 - acc: 0.9269 - val_loss: 0.2186 - val_acc: 0.9295\n",
      "Epoch 2/20\n",
      "24000/24000 [==============================] - 1s 52us/step - loss: 0.1015 - acc: 0.9720 - val_loss: 0.2048 - val_acc: 0.9363\n",
      "Epoch 3/20\n",
      "24000/24000 [==============================] - 1s 56us/step - loss: 0.0528 - acc: 0.9910 - val_loss: 0.2063 - val_acc: 0.9358\n",
      "Epoch 4/20\n",
      "24000/24000 [==============================] - 1s 51us/step - loss: 0.0315 - acc: 0.9970 - val_loss: 0.2072 - val_acc: 0.9362\n",
      "Epoch 5/20\n",
      "24000/24000 [==============================] - 1s 61us/step - loss: 0.0201 - acc: 0.9991 - val_loss: 0.2064 - val_acc: 0.9375\n",
      "Epoch 6/20\n",
      "24000/24000 [==============================] - 1s 60us/step - loss: 0.0144 - acc: 0.9998 - val_loss: 0.2069 - val_acc: 0.9370\n",
      "Epoch 7/20\n",
      "24000/24000 [==============================] - 1s 55us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.2100 - val_acc: 0.9382\n",
      "Epoch 8/20\n",
      "24000/24000 [==============================] - 1s 59us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.2117 - val_acc: 0.9383\n",
      "Epoch 9/20\n",
      "24000/24000 [==============================] - 2s 66us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.2130 - val_acc: 0.9385\n",
      "Epoch 10/20\n",
      "24000/24000 [==============================] - 2s 68us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.2152 - val_acc: 0.9385\n",
      "Epoch 11/20\n",
      "24000/24000 [==============================] - 2s 63us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.2151 - val_acc: 0.9387\n",
      "Epoch 12/20\n",
      "24000/24000 [==============================] - 2s 63us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.2166 - val_acc: 0.9387\n",
      "Epoch 13/20\n",
      "24000/24000 [==============================] - 2s 68us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.2182 - val_acc: 0.9378\n",
      "Epoch 14/20\n",
      "24000/24000 [==============================] - 2s 63us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2207 - val_acc: 0.9383\n",
      "Epoch 15/20\n",
      "24000/24000 [==============================] - 2s 67us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.2219 - val_acc: 0.9383\n",
      "Epoch 16/20\n",
      "24000/24000 [==============================] - 2s 68us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2233 - val_acc: 0.9382\n",
      "Epoch 17/20\n",
      "24000/24000 [==============================] - 1s 58us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.2239 - val_acc: 0.9383\n",
      "Epoch 18/20\n",
      "24000/24000 [==============================] - 1s 61us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.2253 - val_acc: 0.9388\n",
      "Epoch 19/20\n",
      "24000/24000 [==============================] - 2s 68us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.2264 - val_acc: 0.9382\n",
      "Epoch 20/20\n",
      "24000/24000 [==============================] - 2s 69us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.2270 - val_acc: 0.9392\n",
      "Test loss: 0.11883031262120804\n",
      "Test accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "## NOISY_THEN_CLEAN MNIST\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "## Clean portion\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "print(\"Clean data\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = half_clean_mnist #mnist.load_data() \n",
    "\n",
    "x_train = x_train.reshape(30000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "sgd = SGD(lr=0.03, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "## Noisy portion\n",
    "\n",
    "print(\"Noisy data\")\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = half_noisy_mnist #mnist.load_data() \n",
    "\n",
    "x_train = x_train.reshape(30000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "sgd = SGD(lr=0.03, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"keras_mnist_modelv2_one_dense_clean_then_noisy.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noisy_array = []\n",
    "train_data_size = mnist_data[0][0].shape[0]\n",
    "\n",
    "for i in range(0,train_data_size):\n",
    "    train_noisy_array.append(make_noisy(mnist_data[0][0][i]))\n",
    "\n",
    "train_noisy_array = np.asarray(train_noisy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_noisy_array = []\n",
    "test_data_size = mnist_data[1][0].shape[0]\n",
    "\n",
    "for i in range(0,test_data_size):\n",
    "    test_noisy_array.append(make_noisy(mnist_data[1][0][i]))\n",
    "\n",
    "test_noisy_array = np.asarray(test_noisy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=mnist_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=mnist_data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_mnist = ((train_noisy_array, train_labels),(test_noisy_array, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.19710883660701803\n",
      "Test accuracy: 0.9451\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"keras_mnist_modelv2_one_dense_clean_then_noisy.h5\")\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = noisy_mnist #mnist.load_data() \n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On clean mnist, the noisy_then_clean neural network achieved an accuracy of 0.9708\n",
    "\n",
    "## One noisy mnist, the noisy_then_clean neural network achieved an accuracy of 0.9451"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
