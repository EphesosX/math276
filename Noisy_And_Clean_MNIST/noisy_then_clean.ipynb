{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named mkl\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noisy(mnist_image):\n",
    "    mnist_rand_image = np.copy(mnist_image)\n",
    "\n",
    "    for x in np.nditer(mnist_rand_image, op_flags=['readwrite']):\n",
    "        randval = np.random.randint(0,10)\n",
    "        if randval == 0:\n",
    "            x[...] = 0\n",
    "        elif randval == 1:\n",
    "            x[...] = 255\n",
    "            \n",
    "    return mnist_rand_image\n",
    "\n",
    "#plt.imshow(make_noisy(mnist_data[0][0][0]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noisy_clean_array = []\n",
    "train_data_size = mnist_data[0][0].shape[0]\n",
    "validation_split_size = 0.2\n",
    "actual_train_data_size = int(train_data_size * (1 - validation_split_size))\n",
    "\n",
    "# Training set\n",
    "for i in range(0, actual_train_data_size):\n",
    "    if (i < actual_train_data_size/2):\n",
    "        train_noisy_clean_array.append(make_noisy(mnist_data[0][0][i]))\n",
    "    else:\n",
    "        train_noisy_clean_array.append(mnist_data[0][0][i])\n",
    "\n",
    "# Validation set \n",
    "validation_data_size = train_data_size - actual_train_data_size\n",
    "\n",
    "for i in range(0, validation_data_size):\n",
    "    if (i < validation_data_size/2):\n",
    "        train_noisy_clean_array.append(make_noisy(mnist_data[0][0][i+actual_train_data_size]))\n",
    "    else:\n",
    "        train_noisy_clean_array.append(mnist_data[0][0][i+actual_train_data_size])\n",
    "\n",
    "train_noisy_clean_array = np.asarray(train_noisy_clean_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=mnist_data[0][1]\n",
    "test_labels=mnist_data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_then_clean_mnist = ((train_noisy_clean_array,train_labels),(mnist_data[1][0],test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_noisy_mnist_train = noisy_then_clean_mnist[0][0][0:24000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_clean_mnist_train = noisy_then_clean_mnist[0][0][24000:48000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_noisy_mnist_validation = noisy_then_clean_mnist[0][0][48000:48000+6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_clean_mnist_validation = noisy_then_clean_mnist[0][0][48000+6000:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_mnist_half_train_validation = np.concatenate((half_noisy_mnist_train, half_noisy_mnist_validation), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_mnist_half_train_validation = np.concatenate((half_clean_mnist_train, half_clean_mnist_validation), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_for_noisy_train_validation = np.concatenate((train_labels[0:24000],train_labels[48000:48000+6000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_for_clean_train_validation = np.concatenate((train_labels[24000:48000],train_labels[48000+6000:60000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_noisy_mnist = ((noisy_mnist_half_train_validation, labels_for_noisy_train_validation), (mnist_data[1][0], mnist_data[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_clean_mnist = ((clean_mnist_half_train_validation,labels_for_clean_train_validation), (mnist_data[1][0], mnist_data[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean data\n",
      "30000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "24000/24000 [==============================] - 1s 48us/step - loss: 0.6433 - acc: 0.8040 - val_loss: 0.4601 - val_acc: 0.8567\n",
      "Epoch 2/20\n",
      "24000/24000 [==============================] - ETA: 0s - loss: 0.3498 - acc: 0.895 - 1s 46us/step - loss: 0.3500 - acc: 0.8957 - val_loss: 0.4204 - val_acc: 0.8732\n",
      "Epoch 3/20\n",
      "24000/24000 [==============================] - 1s 48us/step - loss: 0.2676 - acc: 0.9215 - val_loss: 0.3976 - val_acc: 0.8767\n",
      "Epoch 4/20\n",
      "24000/24000 [==============================] - 1s 46us/step - loss: 0.2000 - acc: 0.9440 - val_loss: 0.3742 - val_acc: 0.8848\n",
      "Epoch 5/20\n",
      "24000/24000 [==============================] - 1s 50us/step - loss: 0.1468 - acc: 0.9607 - val_loss: 0.3704 - val_acc: 0.8870\n",
      "Epoch 6/20\n",
      "24000/24000 [==============================] - 1s 48us/step - loss: 0.1047 - acc: 0.9770 - val_loss: 0.3586 - val_acc: 0.8930\n",
      "Epoch 7/20\n",
      "24000/24000 [==============================] - 1s 48us/step - loss: 0.0744 - acc: 0.9875 - val_loss: 0.3627 - val_acc: 0.8940\n",
      "Epoch 8/20\n",
      "24000/24000 [==============================] - 1s 49us/step - loss: 0.0526 - acc: 0.9947 - val_loss: 0.3669 - val_acc: 0.8942\n",
      "Epoch 9/20\n",
      "24000/24000 [==============================] - 1s 47us/step - loss: 0.0376 - acc: 0.9978 - val_loss: 0.3648 - val_acc: 0.8968\n",
      "Epoch 10/20\n",
      "24000/24000 [==============================] - 1s 54us/step - loss: 0.0279 - acc: 0.9991 - val_loss: 0.3701 - val_acc: 0.8955\n",
      "Epoch 11/20\n",
      "24000/24000 [==============================] - 1s 50us/step - loss: 0.0211 - acc: 0.9996 - val_loss: 0.3749 - val_acc: 0.8973\n",
      "Epoch 12/20\n",
      "24000/24000 [==============================] - 1s 55us/step - loss: 0.0169 - acc: 0.9998 - val_loss: 0.3784 - val_acc: 0.8972\n",
      "Epoch 13/20\n",
      "24000/24000 [==============================] - 1s 54us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.3803 - val_acc: 0.8985\n",
      "Epoch 14/20\n",
      "24000/24000 [==============================] - 1s 54us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.3838 - val_acc: 0.8995\n",
      "Epoch 15/20\n",
      "24000/24000 [==============================] - 1s 56us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.3893 - val_acc: 0.8995\n",
      "Epoch 16/20\n",
      "24000/24000 [==============================] - 1s 56us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3933 - val_acc: 0.8985\n",
      "Epoch 17/20\n",
      "24000/24000 [==============================] - 1s 58us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3955 - val_acc: 0.9003\n",
      "Epoch 18/20\n",
      "24000/24000 [==============================] - 2s 63us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3980 - val_acc: 0.8998\n",
      "Epoch 19/20\n",
      "24000/24000 [==============================] - 1s 61us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.3995 - val_acc: 0.9005\n",
      "Epoch 20/20\n",
      "24000/24000 [==============================] - 1s 58us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.4017 - val_acc: 0.8998\n",
      "Test loss: 0.21709249304016703\n",
      "Test accuracy: 0.951\n",
      "Noisy data\n",
      "30000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "24000/24000 [==============================] - 1s 58us/step - loss: 0.1622 - acc: 0.9559 - val_loss: 0.1003 - val_acc: 0.9718\n",
      "Epoch 2/20\n",
      "24000/24000 [==============================] - 1s 60us/step - loss: 0.0963 - acc: 0.9730 - val_loss: 0.0913 - val_acc: 0.9722\n",
      "Epoch 3/20\n",
      "24000/24000 [==============================] - 1s 59us/step - loss: 0.0749 - acc: 0.9792 - val_loss: 0.0822 - val_acc: 0.9757\n",
      "Epoch 4/20\n",
      "24000/24000 [==============================] - 1s 62us/step - loss: 0.0599 - acc: 0.9838 - val_loss: 0.0822 - val_acc: 0.9767\n",
      "Epoch 5/20\n",
      "24000/24000 [==============================] - 2s 63us/step - loss: 0.0507 - acc: 0.9873 - val_loss: 0.0840 - val_acc: 0.9763\n",
      "Epoch 6/20\n",
      "24000/24000 [==============================] - 2s 63us/step - loss: 0.0421 - acc: 0.9906 - val_loss: 0.0768 - val_acc: 0.9775\n",
      "Epoch 7/20\n",
      "24000/24000 [==============================] - 1s 62us/step - loss: 0.0351 - acc: 0.9929 - val_loss: 0.0737 - val_acc: 0.9782\n",
      "Epoch 8/20\n",
      "24000/24000 [==============================] - 1s 58us/step - loss: 0.0297 - acc: 0.9948 - val_loss: 0.0730 - val_acc: 0.9793\n",
      "Epoch 9/20\n",
      "24000/24000 [==============================] - 1s 56us/step - loss: 0.0256 - acc: 0.9958 - val_loss: 0.0756 - val_acc: 0.9790\n",
      "Epoch 10/20\n",
      "24000/24000 [==============================] - 1s 56us/step - loss: 0.0231 - acc: 0.9966 - val_loss: 0.0746 - val_acc: 0.9792\n",
      "Epoch 11/20\n",
      "24000/24000 [==============================] - 1s 62us/step - loss: 0.0201 - acc: 0.9975 - val_loss: 0.0757 - val_acc: 0.9787\n",
      "Epoch 12/20\n",
      "24000/24000 [==============================] - 1s 58us/step - loss: 0.0176 - acc: 0.9981 - val_loss: 0.0731 - val_acc: 0.9793\n",
      "Epoch 13/20\n",
      "24000/24000 [==============================] - 2s 64us/step - loss: 0.0156 - acc: 0.9983 - val_loss: 0.0752 - val_acc: 0.9792\n",
      "Epoch 14/20\n",
      "24000/24000 [==============================] - 2s 65us/step - loss: 0.0139 - acc: 0.9989 - val_loss: 0.0722 - val_acc: 0.9793\n",
      "Epoch 15/20\n",
      "24000/24000 [==============================] - 1s 61us/step - loss: 0.0125 - acc: 0.9993 - val_loss: 0.0725 - val_acc: 0.9787\n",
      "Epoch 16/20\n",
      "24000/24000 [==============================] - 2s 64us/step - loss: 0.0112 - acc: 0.9993 - val_loss: 0.0734 - val_acc: 0.9790\n",
      "Epoch 17/20\n",
      "24000/24000 [==============================] - 2s 63us/step - loss: 0.0104 - acc: 0.9993 - val_loss: 0.0735 - val_acc: 0.9795\n",
      "Epoch 18/20\n",
      "24000/24000 [==============================] - 2s 66us/step - loss: 0.0093 - acc: 0.9995 - val_loss: 0.0750 - val_acc: 0.9788\n",
      "Epoch 19/20\n",
      "24000/24000 [==============================] - 2s 63us/step - loss: 0.0086 - acc: 0.9998 - val_loss: 0.0745 - val_acc: 0.9798\n",
      "Epoch 20/20\n",
      "24000/24000 [==============================] - 2s 65us/step - loss: 0.0081 - acc: 0.9997 - val_loss: 0.0735 - val_acc: 0.9792\n",
      "Test loss: 0.08046303191556363\n",
      "Test accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "## NOISY_THEN_CLEAN MNIST\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "## Clean portion\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "print(\"Clean data\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = half_noisy_mnist #mnist.load_data() \n",
    "\n",
    "x_train = x_train.reshape(30000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "sgd = SGD(lr=0.03, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "## Noisy portion\n",
    "\n",
    "print(\"Noisy data\")\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = half_clean_mnist #mnist.load_data() \n",
    "\n",
    "x_train = x_train.reshape(30000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "sgd = SGD(lr=0.03, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"keras_mnist_modelv2_one_dense_noisy_then_clean.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noisy_array = []\n",
    "train_data_size = mnist_data[0][0].shape[0]\n",
    "\n",
    "for i in range(0,train_data_size):\n",
    "    train_noisy_array.append(make_noisy(mnist_data[0][0][i]))\n",
    "\n",
    "train_noisy_array = np.asarray(train_noisy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_noisy_array = []\n",
    "test_data_size = mnist_data[1][0].shape[0]\n",
    "\n",
    "for i in range(0,test_data_size):\n",
    "    test_noisy_array.append(make_noisy(mnist_data[1][0][i]))\n",
    "\n",
    "test_noisy_array = np.asarray(test_noisy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=mnist_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=mnist_data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_mnist = ((train_noisy_array, train_labels),(test_noisy_array, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5047540784716606\n",
      "Test accuracy: 0.844\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"keras_mnist_modelv2_one_dense_noisy_then_clean.h5\")\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = noisy_mnist #mnist.load_data() \n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On clean mnist, the noisy_then_clean neural network achieved an accuracy of 0.9778\n",
    "\n",
    "## One noisy mnist, the noisy_then_clean neural network achieved an accuracy of 0.844"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
